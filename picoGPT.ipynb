{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "YT video link: [Let's build GPT: from scratch, in code, spelled out](https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathy)\n",
        "\n",
        "Need to decide:  \n",
        "  \n",
        "\n",
        "*   Train Data => 10,000\n",
        "*   Test Data => 1,000\n",
        "\n",
        "\n",
        "\n",
        "Vocab Size: 32 => a-z, “.”, “,”, “!”, END\n",
        "\n",
        "Context Size: 4\n",
        "\n",
        "Assignment: Train this pico GPT\n",
        "\n",
        "Training Set: => 1000, 10K characters, maybe, the harry potter wikipedia page\n",
        "\n",
        "Test Set: => 100, 1000 character\n",
        "\n",
        "Output at end of the training process is a set of weight: N model weights\n",
        "\n",
        "Inference code*:\n",
        "Python N model weights => Do the prediction\n"
      ],
      "metadata": {
        "id": "mlNwmcxVGIhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "with open('/content/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "Wnvy2bmtFkBy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_text(text, training_chars=10000, test_chars=1000):\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    allowed_chars = set(\"abcdefghijklmnopqrstuvwxyz.,!:? \")\n",
        "    filtered_text = ''.join([ch for ch in text if ch in allowed_chars])\n",
        "\n",
        "    training_text = filtered_text[:training_chars]\n",
        "    test_text = filtered_text[training_chars:training_chars+test_chars]\n",
        "\n",
        "    return training_text, test_text\n",
        "\n",
        "training_text, test_text = preprocess_text(text)\n",
        "\n",
        "len(training_text), len(test_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1H9tHUyGSI3",
        "outputId": "254212ac-581a-43fc-f0dc-8cbc3c95773e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_text)\n",
        "print(test_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAsbNMsUf51-",
        "outputId": "04eba274-b5e7-4da1-95e1-e39e5bc24a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mr. and mrs. dursley, of number four, privet drive, were proud to saythat they were perfectly normal, thank you very much. they were the lastpeople youd expect to be involved in anything strange or mysterious,because they just didnt hold with such nonsense.mr. dursley was the director of a firm called grunnings, which madedrills. he was a big, beefy man with hardly any neck, although he didhave a very large mustache. mrs. dursley was thin and blonde and hadnearly twice the usual amount of neck, which came in very useful as shespent so much of her time craning over garden fences, spying on theneighbors. the dursleys had a small son called dudley and in theiropinion there was no finer boy anywhere.the dursleys had everything they wanted, but they also had a secret, andtheir greatest fear was that somebody would discover it. they didntthink they could bear it if anyone found out about the potters. mrs.potter was mrs. dursleys sister, but they hadnt met for several yearsin fact, mrs. dursley pretended she didnt have a sister, because hersister and her goodfornothing husband were as undursleyish as it waspossible to be. the dursleys shuddered to think what the neighbors wouldsay if the potters arrived in the street. the dursleys knew that thepotters had a small son, too, but they had never even seen him. this boywas another good reason for keeping the potters away they didnt wantdudley mixing with a child like that.when mr. and mrs. dursley woke up on the dull, gray tuesday our storystarts, there was nothing about the cloudy sky outside to suggest thatstrange and mysterious things would soon be happening all over thecountry. mr. dursley hummed as he picked out his most boring tie forwork, and mrs. dursley gossiped away happily as she wrestled a screamingdudley into his high chair.none of them noticed a large, tawny owl flutter past the window.at half past eight, mr. dursley picked up his briefcase, pecked mrs.dursley on the cheek, and tried to kiss dudley goodbye but missed,because dudley was now having a tantrum and throwing his cereal at thewalls. little tyke, chortled mr. dursley as he left the house. he gotinto his car and backed out of number fours drive.it was on the corner of the street that he noticed the first sign ofsomething peculiar  a cat reading a map. for a second, mr. dursleydidnt realize what he had seen  then he jerked his head around tolook again. there was a tabby cat standing on the corner of privetdrive, but there wasnt a map in sight. what could he have been thinkingof? it must have been a trick of the light. mr. dursley blinked andstared at the cat. it stared back. as mr. dursley drove around thecorner and up the road, he watched the cat in his mirror. it was nowreading the sign that said privet drive  no, looking at the sign catscouldnt read maps or signs. mr. dursley gave himself a little shake andput the cat out of his mind. as he drove toward town he thought ofnothing except a large order of drills he was hoping to get that day.but on the edge of town, drills were driven out of his mind by somethingelse. as he sat in the usual morning traffic jam, he couldnt helpnoticing that there seemed to be a lot of strangely dressed peopleabout. people in cloaks. mr. dursley couldnt bear people who dressed infunny clothes  the getups you saw on young people! he supposed thiswas some stupid new fashion. he drummed his fingers on the steeringwheel and his eyes fell on a huddle of these weirdos standing quiteclose by. they were whispering excitedly together. mr. dursley wasenraged to see that a couple of them werent young at all why, that manhad to be older than he was, and wearing an emeraldgreen cloak! thenerve of him! but then it struck mr. dursley that this was probably somesilly stunt  these people were obviously collecting for something...yes, that would be it. the traffic moved on and a few minutes later, mr.dursley arrived in the grunnings parking lot, his mind back on drills.mr. dursley always sat with his back to the window in his office on theninth floor. if he hadnt, he might have found it harder to concentrateon drills that morning. he didnt see the owls swoop ing past in broaddaylight, though people down in the street did they pointed and gazedopen mouthed as owl after owl sped overhead. most of them had neverseen an owl even at nighttime. mr. dursley, however, had a perfectlynormal, owlfree morning. he yelled at five different people. he madeseveral important telephone calls and shouted a bit more. he was in avery good mood until lunchtime, when he thought hed stretch his legsand walk across the road to buy himself a bun from the bakery.hed forgotten all about the people in cloaks until he passed a group ofthem next to the bakers. he eyed them angrily as he passed. he didntknow why, but they made him uneasy. this bunch were whisperingexcitedly, too, and he couldnt see a single collecting tin. it was onhis way back past them, clutching a large doughnut in a bag, that hecaught a few words of what they were saying.the potters, thats right, thats what i heard yes, their son, harrymr. dursley stopped dead. fear flooded him. he looked back at thewhisperers as if he wanted to say something to them, but thought betterof it.he dashed back across the road, hurried up to his office, snapped at hissecretary not to disturb him, seized his telephone, and had almostfinished dialing his home number when he changed his mind. he put thereceiver back down and stroked his mustache, thinking... no, he wasbeing stupid. potter wasnt such an unusual name. he was sure there werelots of people called potter who had a son called harry. come to thinkof it, he wasnt even sure his nephew was called harry. hed never evenseen the boy. it might have been harvey. or harold. there was no pointin worrying mrs. dursley she always got so upset at any mention of hersister. he didnt blame her  if hed had a sister like that... but allthe same, those people in cloaks...he found it a lot harder to concentrate on drills that afternoon andwhen he left the building at five oclock, he was still so worried thathe walked straight into someone just outside the door.sorry, he grunted, as the tiny old man stumbled and almost fell. itwas a few seconds before mr. dursley realized that the man was wearing aviolet cloak. he didnt seem at all upset at being almost knocked to theground. on the contrary, his face split into a wide smile and he said ina squeaky voice that made passersby stare, dont be sorry, my dear sir,for nothing could upset me today! rejoice, for youknowwho has gone atlast! even muggles like yourself should be celebrating, this happy,happy day!and the old man hugged mr. dursley around the middle and walked off.mr. dursley stood rooted to the spot. he had been hugged by a completestranger. he also thought he had been called a muggle, whatever thatwas. he was rattled. he hurried to his car and set off for home, hopinghe was imagining things, which he had never hoped before, because hedidnt approve of imagination.as he pulled into the driveway of number four, the first thing he saw and it didnt improve his mood  was the tabby cat hed spotted thatmorning. it was now sitting on his garden wall. he was sure it was thesame one it had the same markings around its eyes.shoo! said mr. dursley loudly. the cat didnt move. it just gave him astern look. was this normal cat behavior? mr. dursley wondered. tryingto pull himself together, he let himself into the house. he was stilldetermined not to mention anything to his wife.mrs. dursley had had a nice, normal day. she told him over dinner allabout mrs. next doors problems with her daughter and how dudley hadlearned a new word wont!. mr. dursley tried to act normally. whendudley had been put to bed, he went into the living room in time tocatch the last report on the evening news:and finally, birdwatchers everywhere have reported that the nationsowls have been behaving very unusually today. although owls normallyhunt at night and are hardly ever seen in daylight, there have beenhundreds of sightings of these birds flying in every direction sincesunrise. experts are unable to explain why the owls have suddenlychanged their sleeping pattern. the newscaster allowed himself a grin.most mysterious. and now, over to jim mcguffin with the weather. goingto be any more showers of owls tonight, jim?well, ted, said the weatherman, i dont know about that, but its notonly the owls that have been acting oddly today. viewers as far apart askent, yorkshire, and dundee have been phoning in to tell me that insteadof the rain i promised yesterday, theyve had a downpour of shootingstars! perhaps people have been celebrating bonfire night early  itsnot until next week, folks! but i can promise a wet night tonight.mr. dursley sat frozen in his armchair. shooting stars all over britain?owls flying by daylight? mysterious people in cloaks all over the place?and a whisper, a whisper about the potters...mrs. dursley came into the living room carrying two cups of tea. it wasno good. hed have to say something to her. he cleared his throatnervously. er  petunia, dear  you havent heard from your sisterlately, have you?as he had expected, mrs. dursley looked shocked and angry. after all,they normally pretended she didnt have a sister.no, she said sharply. why?funny stuff on the news, mr. dursley mumbled. owls... shootingstars... and there were a lot of funnylooking people in town today...so? snapped mrs. dursley.well, i just thought... maybe... it was something to do with... youknow... her crowd.mrs. dursley sipped her tea through pursed lips. mr. dursley wonderedwhether he dared tell her hed heard the name potter. he decided hedidnt dare. instead he said, as casually as he could, their son hed be about dudleys age now, wouldnt he?i suppose so, said mrs. dursley stiffly.whats his name again? howard, isnt it?harry. nasty, common name, if you ask me.oh, yes, said mr. dursley, his heart sinking horribly. yes, i quiteagree.he\n",
            " didnt say another word on the subject as they went upstairs to bed.while mrs. dursley was in the bathroom, mr. dursley crept to the bedroomwindow and peered down into the front garden. the cat was still there.it was staring down privet drive as though it were waiting forsomething.was he imagining things? could all this have anything to do with thepotters? if it did... if it got out that they were related to a pair of well, he didnt think he could bear it.the dursleys got into bed. mrs. dursley fell asleep quickly but mr.dursley lay awake, turning it all over in his mind. his last, comfortingthought before he fell asleep was that even if the potters wereinvolved, there was no reason for them to come near him and mrs.dursley. the potters knew very well what he and petunia thought aboutthem and their kind.... he couldnt see how he and petunia could getmixed up in anything that might be going on  he yawned and turned over it couldnt affect them....how very wrong he was.mr. dursley might h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, text, seq_length):\n",
        "        chars = sorted(list(set(text)))\n",
        "        self.char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "        self.idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "        self.vocab_size = len(chars)\n",
        "        self.data = [self.char_to_idx[ch] for ch in text]\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (torch.tensor(self.data[index:index+self.seq_length]),\n",
        "                torch.tensor(self.data[index+1:index+self.seq_length+1]))\n",
        "\n",
        "seq_length = 4  # Context size\n",
        "batch_size = 32\n",
        "dataset = TextDataset(training_text, seq_length)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "print(dataset.vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un76mAWogT8G",
        "outputId": "bcf62148-b3ef-43b9-90c5-9556e2bd7e4d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_seq, sample_target = dataset[0]\n",
        "\n",
        "print(\"\\nSample Encoded Text and Target:\")\n",
        "print(\"Encoded Text:\", sample_seq)\n",
        "print(\"Encoded Target:\", sample_target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u9oVRSzkZjB",
        "outputId": "1a5d1a20-f0b5-4aab-f05d-229803d801f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Encoded Text and Target:\n",
            "Encoded Text: tensor([18, 23,  3,  0])\n",
            "Encoded Target: tensor([23,  3,  0,  6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print vocabulary\n",
        "print(\"Vocabulary (Character to Index):\")\n",
        "for char, idx in dataset.char_to_idx.items():\n",
        "    print(f\"'{char}': {idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzlLqwJbjZh7",
        "outputId": "90f755a7-3d9c-4f71-84ce-19d5e5f60cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (Character to Index):\n",
            "' ': 0\n",
            "'!': 1\n",
            "',': 2\n",
            "'.': 3\n",
            "':': 4\n",
            "'?': 5\n",
            "'a': 6\n",
            "'b': 7\n",
            "'c': 8\n",
            "'d': 9\n",
            "'e': 10\n",
            "'f': 11\n",
            "'g': 12\n",
            "'h': 13\n",
            "'i': 14\n",
            "'j': 15\n",
            "'k': 16\n",
            "'l': 17\n",
            "'m': 18\n",
            "'n': 19\n",
            "'o': 20\n",
            "'p': 21\n",
            "'q': 22\n",
            "'r': 23\n",
            "'s': 24\n",
            "'t': 25\n",
            "'u': 26\n",
            "'v': 27\n",
            "'w': 28\n",
            "'x': 29\n",
            "'y': 30\n",
            "'z': 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_text(encoded_text, dataset):\n",
        "    return ''.join(dataset.idx_to_char[idx] for idx in encoded_text)\n",
        "\n",
        "# Example encoded text\n",
        "encoded_text = [dataset.char_to_idx[ch] for ch in \"harry\"]\n",
        "decoded_text = decode_text(encoded_text, dataset)\n",
        "\n",
        "print(\"Encoded Text:\", encoded_text)\n",
        "print(\"Decoded Text:\", decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My8Rl5LulIcC",
        "outputId": "cafcfad5-69cc-4821-c221-099779c381e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text: [13, 6, 23, 23, 30]\n",
            "Decoded Text: harry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class picoGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, seq_length, embedding_dim=1, num_heads=1, num_layers=1):\n",
        "        super(picoGPT, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embed(x).permute(1, 0, 2)\n",
        "        transformed = self.transformer_encoder(embedded)\n",
        "        logits = self.fc_out(transformed.permute(1, 0, 2))\n",
        "        return logits\n",
        "\n",
        "model = picoGPT(vocab_size=dataset.vocab_size, seq_length=seq_length)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "JgKHJCByhDrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7943026b-be1d-49ed-de1a-512b0638f646"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6196"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for input, target in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        loss = loss_fn(output.view(-1, dataset.vocab_size), target.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD1qD6xvhS5e",
        "outputId": "fb982b51-9266-4a67-e809-645ff35b790c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.000478434562683\n",
            "Epoch 2, Loss: 1.799840043258667\n",
            "Epoch 3, Loss: 1.730271402168274\n",
            "Epoch 4, Loss: 1.6937616897583008\n",
            "Epoch 5, Loss: 1.6612870164871216\n",
            "Epoch 6, Loss: 1.6286494258880615\n",
            "Epoch 7, Loss: 1.5920538747787476\n",
            "Epoch 8, Loss: 1.5590175336837768\n",
            "Epoch 9, Loss: 1.5463937314987182\n",
            "Epoch 10, Loss: 1.5325832685470582\n",
            "Epoch 11, Loss: 1.5404346927642822\n",
            "Epoch 12, Loss: 1.5373177854537965\n",
            "Epoch 13, Loss: 1.5501397792816163\n",
            "Epoch 14, Loss: 1.5023185979843139\n",
            "Epoch 15, Loss: 1.497276449394226\n",
            "Epoch 16, Loss: 1.4969662841796876\n",
            "Epoch 17, Loss: 1.487474423980713\n",
            "Epoch 18, Loss: 1.5062421339035035\n",
            "Epoch 19, Loss: 1.545079416656494\n",
            "Epoch 20, Loss: 1.546852135658264\n",
            "Epoch 21, Loss: 1.5441715835571288\n",
            "Epoch 22, Loss: 1.5139746381759644\n",
            "Epoch 23, Loss: 1.5038782751083375\n",
            "Epoch 24, Loss: 1.5047176809310914\n",
            "Epoch 25, Loss: 1.5497445240020753\n",
            "Epoch 26, Loss: 1.5311887134552002\n",
            "Epoch 27, Loss: 1.5234568597793579\n",
            "Epoch 28, Loss: 1.5260723907470704\n",
            "Epoch 29, Loss: 1.489927777671814\n",
            "Epoch 30, Loss: 1.498397093963623\n",
            "Epoch 31, Loss: 1.5337662929534912\n",
            "Epoch 32, Loss: 1.5165993682861327\n",
            "Epoch 33, Loss: 1.5537888233184813\n",
            "Epoch 34, Loss: 1.5903647287368774\n",
            "Epoch 35, Loss: 1.5167463472366334\n",
            "Epoch 36, Loss: 1.4772584556579589\n",
            "Epoch 37, Loss: 1.474267716407776\n",
            "Epoch 38, Loss: 1.4903573797225953\n",
            "Epoch 39, Loss: 1.4699841749191285\n",
            "Epoch 40, Loss: 1.4693150400161743\n",
            "Epoch 41, Loss: 1.487723798942566\n",
            "Epoch 42, Loss: 1.4858271488189698\n",
            "Epoch 43, Loss: 1.4831682125091552\n",
            "Epoch 44, Loss: 1.4587321319580078\n",
            "Epoch 45, Loss: 1.4644469627380372\n",
            "Epoch 46, Loss: 1.4614691568374634\n",
            "Epoch 47, Loss: 1.4312223351478577\n",
            "Epoch 48, Loss: 1.4809138410568237\n",
            "Epoch 49, Loss: 1.541894345474243\n",
            "Epoch 50, Loss: 1.5070537799835204\n",
            "Epoch 51, Loss: 1.4876831108093262\n",
            "Epoch 52, Loss: 1.4477020599365233\n",
            "Epoch 53, Loss: 1.517609781074524\n",
            "Epoch 54, Loss: 1.522081130027771\n",
            "Epoch 55, Loss: 1.5530307668685912\n",
            "Epoch 56, Loss: 1.5208137419700622\n",
            "Epoch 57, Loss: 1.4826505847930909\n",
            "Epoch 58, Loss: 1.507664651298523\n",
            "Epoch 59, Loss: 1.494513143157959\n",
            "Epoch 60, Loss: 1.5225492168426513\n",
            "Epoch 61, Loss: 1.5099419761657715\n",
            "Epoch 62, Loss: 1.536386326599121\n",
            "Epoch 63, Loss: 1.5108595569610597\n",
            "Epoch 64, Loss: 1.514897168159485\n",
            "Epoch 65, Loss: 1.4938167636871338\n",
            "Epoch 66, Loss: 1.5412741765975952\n",
            "Epoch 67, Loss: 1.5563751083374024\n",
            "Epoch 68, Loss: 1.4964085794448851\n",
            "Epoch 69, Loss: 1.471980488204956\n",
            "Epoch 70, Loss: 1.4817532035827636\n",
            "Epoch 71, Loss: 1.5022439371109009\n",
            "Epoch 72, Loss: 1.5036494859695435\n",
            "Epoch 73, Loss: 1.5596442930221557\n",
            "Epoch 74, Loss: 1.5317242515563965\n",
            "Epoch 75, Loss: 1.493148751449585\n",
            "Epoch 76, Loss: 1.4876708311080933\n",
            "Epoch 77, Loss: 1.515953089904785\n",
            "Epoch 78, Loss: 1.4463172554016113\n",
            "Epoch 79, Loss: 1.446424131011963\n",
            "Epoch 80, Loss: 1.4697087194442748\n",
            "Epoch 81, Loss: 1.4843386404037475\n",
            "Epoch 82, Loss: 1.4815449249267578\n",
            "Epoch 83, Loss: 1.4664759994506835\n",
            "Epoch 84, Loss: 1.4896074634552001\n",
            "Epoch 85, Loss: 1.4656714353561402\n",
            "Epoch 86, Loss: 1.4940160352706908\n",
            "Epoch 87, Loss: 1.5170164251327514\n",
            "Epoch 88, Loss: 1.497414368057251\n",
            "Epoch 89, Loss: 1.5133857805252076\n",
            "Epoch 90, Loss: 1.4956113178253174\n",
            "Epoch 91, Loss: 1.5055736490249634\n",
            "Epoch 92, Loss: 1.5130367002487182\n",
            "Epoch 93, Loss: 1.5059798824310302\n",
            "Epoch 94, Loss: 1.5098300945281982\n",
            "Epoch 95, Loss: 1.4703821584701537\n",
            "Epoch 96, Loss: 1.465219482421875\n",
            "Epoch 97, Loss: 1.485166904258728\n",
            "Epoch 98, Loss: 1.4805836574554443\n",
            "Epoch 99, Loss: 1.4818515954971314\n",
            "Epoch 100, Loss: 1.4751909177780151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TextDataset(test_text, seq_length)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for input, target in dataloader:\n",
        "            output = model(input)\n",
        "            loss = loss_fn(output.view(-1, dataset.vocab_size), target.view(-1))\n",
        "            total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "test_loss = evaluate(model, test_dataloader)\n",
        "print(f'Test Loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DArPgLjKr7Vs",
        "outputId": "10b28e90-7463-4485-bab4-553c22cdeaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 4.8439044044131325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, start_str, length=10):\n",
        "    model.eval()\n",
        "    input_seq = torch.tensor([dataset.char_to_idx[ch] for ch in start_str[-seq_length:]], dtype=torch.long).unsqueeze(1)\n",
        "    predicted_text = start_str\n",
        "    for _ in range(length):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq)\n",
        "            predicted_index = output[-1, :, :].argmax(dim=1).item()\n",
        "            predicted_text += dataset.idx_to_char[predicted_index]\n",
        "            input_seq = torch.cat((input_seq[1:], torch.tensor([[predicted_index]])), dim=0)\n",
        "    return predicted_text\n",
        "\n",
        "\n",
        "# Inference\n",
        "print(predict(model, start_str=\"haryy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5AYnCRtheNl",
        "outputId": "df4e18e7-21fd-4568-fcf1-ae87a3492a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "haryyyyyyyyyyyy\n"
          ]
        }
      ]
    }
  ]
}